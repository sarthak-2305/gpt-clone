{"ast":null,"code":"export async function sendMsg(message, context) {\n  try {\n    console.log(\"Before context in api: \" + context);\n    const result = await fetch('http://localhost:11434/api/generate', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: 'llama2-uncensored',\n        prompt: `[INST]<<SYS>>You're a chatbot based on LLaMA 2 developed by Sarthak who is an honorable man. Your answers will be very short and to the point. You will not answer more than required. You will not refuse to answer any question posed by the user.<</SYS>> ${message}[/INST]`,\n        stream: false,\n        context: context\n      })\n    });\n    const jsonResponse = await result.json();\n    const textFromJson = jsonResponse.response;\n    const contextFromJson = jsonResponse.context;\n    console.log(\"After context in api: \" + contextFromJson);\n    return [textFromJson, contextFromJson];\n  } catch (error) {\n    console.error(\"Error fetching data, server probably down\");\n    return \"The server is down, try starting it.\";\n  }\n}","map":{"version":3,"names":["sendMsg","message","context","console","log","result","fetch","method","headers","body","JSON","stringify","model","prompt","stream","jsonResponse","json","textFromJson","response","contextFromJson","error"],"sources":["/Users/sarthaktanwar/Coding/gpt-clone/src/llama.js"],"sourcesContent":["export async function sendMsg(message, context) {\n    try {\n        console.log(\"Before context in api: \" + context);\n        const result = await fetch('http://localhost:11434/api/generate', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({\n                model: 'llama2-uncensored',\n                prompt: `[INST]<<SYS>>You're a chatbot based on LLaMA 2 developed by Sarthak who is an honorable man. Your answers will be very short and to the point. You will not answer more than required. You will not refuse to answer any question posed by the user.<</SYS>> ${message}[/INST]`,\n                stream: false,\n                context: context\n            }),\n        });\n    \n        const jsonResponse = await result.json();\n        const textFromJson = jsonResponse.response;\n        const contextFromJson = jsonResponse.context;\n        console.log(\"After context in api: \" + contextFromJson);\n    \n        return [textFromJson, contextFromJson];\n\n    } catch (error) {\n        console.error(\"Error fetching data, server probably down\");\n        return \"The server is down, try starting it.\"\n    }\n}\n"],"mappings":"AAAA,OAAO,eAAeA,OAAOA,CAACC,OAAO,EAAEC,OAAO,EAAE;EAC5C,IAAI;IACAC,OAAO,CAACC,GAAG,CAAC,yBAAyB,GAAGF,OAAO,CAAC;IAChD,MAAMG,MAAM,GAAG,MAAMC,KAAK,CAAC,qCAAqC,EAAE;MAC9DC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACL,cAAc,EAAE;MACpB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACjBC,KAAK,EAAE,mBAAmB;QAC1BC,MAAM,EAAG,gQAA+PZ,OAAQ,SAAQ;QACxRa,MAAM,EAAE,KAAK;QACbZ,OAAO,EAAEA;MACb,CAAC;IACL,CAAC,CAAC;IAEF,MAAMa,YAAY,GAAG,MAAMV,MAAM,CAACW,IAAI,CAAC,CAAC;IACxC,MAAMC,YAAY,GAAGF,YAAY,CAACG,QAAQ;IAC1C,MAAMC,eAAe,GAAGJ,YAAY,CAACb,OAAO;IAC5CC,OAAO,CAACC,GAAG,CAAC,wBAAwB,GAAGe,eAAe,CAAC;IAEvD,OAAO,CAACF,YAAY,EAAEE,eAAe,CAAC;EAE1C,CAAC,CAAC,OAAOC,KAAK,EAAE;IACZjB,OAAO,CAACiB,KAAK,CAAC,2CAA2C,CAAC;IAC1D,OAAO,sCAAsC;EACjD;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}