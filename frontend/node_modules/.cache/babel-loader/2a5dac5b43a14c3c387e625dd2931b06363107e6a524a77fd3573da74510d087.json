{"ast":null,"code":"export async function sendMsg(message) {\n  const result = await fetch('http://localhost:11434/api/generate', {\n    method: 'POST',\n    headers: {\n      'Content-Type': 'application/json'\n    },\n    body: JSON.stringify({\n      model: 'llama2',\n      prompt: message,\n      stream: false\n    })\n  });\n  const jsonResponse = await result.json();\n  const textFromJson = jsonResponse.response;\n  return textFromJson;\n}","map":{"version":3,"names":["sendMsg","message","result","fetch","method","headers","body","JSON","stringify","model","prompt","stream","jsonResponse","json","textFromJson","response"],"sources":["/Users/sarthaktanwar/Coding/gpt-clone/src/llama.js"],"sourcesContent":["export async function sendMsg(message) {\n    const result = await fetch('http://localhost:11434/api/generate', {\n        method: 'POST',\n        headers: {\n            'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n            model: 'llama2',\n            prompt: message,\n            stream: false,\n        }),\n    });\n\n    const jsonResponse = await result.json();\n    const textFromJson = jsonResponse.response;\n\n    return textFromJson;\n}\n"],"mappings":"AAAA,OAAO,eAAeA,OAAOA,CAACC,OAAO,EAAE;EACnC,MAAMC,MAAM,GAAG,MAAMC,KAAK,CAAC,qCAAqC,EAAE;IAC9DC,MAAM,EAAE,MAAM;IACdC,OAAO,EAAE;MACL,cAAc,EAAE;IACpB,CAAC;IACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;MACjBC,KAAK,EAAE,QAAQ;MACfC,MAAM,EAAET,OAAO;MACfU,MAAM,EAAE;IACZ,CAAC;EACL,CAAC,CAAC;EAEF,MAAMC,YAAY,GAAG,MAAMV,MAAM,CAACW,IAAI,CAAC,CAAC;EACxC,MAAMC,YAAY,GAAGF,YAAY,CAACG,QAAQ;EAE1C,OAAOD,YAAY;AACvB"},"metadata":{},"sourceType":"module","externalDependencies":[]}